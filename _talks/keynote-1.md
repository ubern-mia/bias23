---
name: Keynote - The need for interpretability in clinical decision support
speakers:
  - Henning MÃ¼ller
categories:
  - Keynotes
---

Classical machine learning using handcrafted features or decision trees that were used in clinical decision support could be interpreted by design. When deep neural networks led to much better results in many tasks but as black box models it became clear that a machine learning decision without any explication can hardly be integrated with the way clinical work such as diagnosis or treatment planning is done. Interpretability/explainability has become a major challenge for using any tool in clinical practice. The presentation will start with the basic challenges of systematic medical data analysis and go towards integrating explainable AI into modern solutions of digital medicine.

<iframe width="560" height="315" src="https://www.youtube.com/embed/XgeeHPdOYSI?si=1w8LFhYtMu-vAM28" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>